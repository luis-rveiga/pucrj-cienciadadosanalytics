{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para não exibir os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga do dataset\n",
    "uci_url = 'https://archive.ics.uci.edu/static/public/697/'\n",
    "predict_student_file = 'predict+students+dropout+and+academic+success.zip'\n",
    "request = urllib.request.urlopen(uci_url + urllib.parse.quote(predict_student_file))\n",
    "zipfile = ZipFile(BytesIO(request.read()))\n",
    "filepath = TextIOWrapper(zipfile.open('data.csv'), encoding='utf-8')\n",
    "dataset = pd.read_csv(filepath, sep=';')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados\n",
    "\n",
    "# Separação em bases de treino e teste (holdout)\n",
    "array = dataset.values\n",
    "X = array[:,0:36]\n",
    "y = array[:,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número original de atributos: 36\n",
      "\n",
      "Número reduzido de atributos: 15\n",
      "\n",
      "Atributos Originais: Index(['Marital status', 'Application mode', 'Application order', 'Course',\n",
      "       'Daytime/evening attendance\\t', 'Previous qualification',\n",
      "       'Previous qualification (grade)', 'Nacionality',\n",
      "       'Mother's qualification', 'Father's qualification',\n",
      "       'Mother's occupation', 'Father's occupation', 'Admission grade',\n",
      "       'Displaced', 'Educational special needs', 'Debtor',\n",
      "       'Tuition fees up to date', 'Gender', 'Scholarship holder',\n",
      "       'Age at enrollment', 'International',\n",
      "       'Curricular units 1st sem (credited)',\n",
      "       'Curricular units 1st sem (enrolled)',\n",
      "       'Curricular units 1st sem (evaluations)',\n",
      "       'Curricular units 1st sem (approved)',\n",
      "       'Curricular units 1st sem (grade)',\n",
      "       'Curricular units 1st sem (without evaluations)',\n",
      "       'Curricular units 2nd sem (credited)',\n",
      "       'Curricular units 2nd sem (enrolled)',\n",
      "       'Curricular units 2nd sem (evaluations)',\n",
      "       'Curricular units 2nd sem (approved)',\n",
      "       'Curricular units 2nd sem (grade)',\n",
      "       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',\n",
      "       'Inflation rate', 'GDP'],\n",
      "      dtype='object')\n",
      "\n",
      "Scores dos Atributos Originais: [1.983e+01 1.145e+02 1.973e+01 2.671e+00 1.445e+01 7.005e+00 2.773e+01\n",
      " 8.362e-01 1.282e+01 3.838e+00 9.838e+00 8.968e+00 3.565e+01 2.924e+01\n",
      " 3.209e-01 1.376e+02 5.056e+02 1.230e+02 2.258e+02 1.547e+02 6.397e-01\n",
      " 7.979e+00 5.947e+01 3.753e+01 8.599e+02 7.135e+02 1.144e+01 9.975e+00\n",
      " 7.559e+01 8.780e+01 1.411e+03 1.134e+03 2.019e+01 5.923e+00 1.742e+00\n",
      " 4.799e+00]\n",
      "\n",
      "Atributos Selecionados: ['Application mode' 'Admission grade' 'Debtor' 'Tuition fees up to date'\n",
      " 'Gender' 'Scholarship holder' 'Age at enrollment'\n",
      " 'Curricular units 1st sem (enrolled)'\n",
      " 'Curricular units 1st sem (evaluations)'\n",
      " 'Curricular units 1st sem (approved)' 'Curricular units 1st sem (grade)'\n",
      " 'Curricular units 2nd sem (enrolled)'\n",
      " 'Curricular units 2nd sem (evaluations)'\n",
      " 'Curricular units 2nd sem (approved)' 'Curricular units 2nd sem (grade)']\n"
     ]
    }
   ],
   "source": [
    "# Seleção de atributos usando Seleção Univariada\n",
    "\n",
    "# Calculando o melhor k\n",
    "f1_score_list = []\n",
    "\n",
    "model_LR = LogisticRegression(max_iter=200)\n",
    "\n",
    "for k in range(1, 37):\n",
    "    # Seleção de atributos com SelectKBest\n",
    "    kbest_var = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "    # Executa a função de pontuação e obtém os atributos selecionados\n",
    "    kbest_var.fit(X, y)\n",
    "\n",
    "    # Reduz X para os atributos selecionados\n",
    "    features = kbest_var.transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "    model_LR.fit(X_train, y_train)\n",
    "    kbest_pred = model_LR.predict(X_test)    \n",
    "\n",
    "    f1_score_kbest = round(f1_score(y_test, kbest_pred, average='weighted'), 3)\n",
    "    f1_score_list.append(f1_score_kbest)\n",
    "\n",
    "# O melhor k selecionado\n",
    "kbest = f1_score_list.index(max(f1_score_list)) + 1\n",
    "\n",
    "# Seleção de atributos com o melhor k\n",
    "kbest_var = SelectKBest(score_func=f_classif, k=kbest)\n",
    "\n",
    "# Executa a função de pontuação em (X, y) e obtém os atributos selecionados\n",
    "fit = kbest_var.fit(X, y)\n",
    "\n",
    "# Reduz X para os atributos selecionados\n",
    "features = fit.transform(X)\n",
    "\n",
    "# resultados\n",
    "print('\\nNúmero original de atributos:', X.shape[1])\n",
    "print('\\nNúmero reduzido de atributos:', features.shape[1])\n",
    "\n",
    "# Exibe os atributos originais\n",
    "print(\"\\nAtributos Originais:\", dataset.columns[0:36])\n",
    "\n",
    "# Exibe as pontuações de cada atributo e os escolhidos (com as pontuações mais altas)\n",
    "np.set_printoptions(precision=3) \n",
    "print(\"\\nScores dos Atributos Originais:\", fit.scores_)\n",
    "print(\"\\nAtributos Selecionados:\", kbest_var.get_feature_names_out(input_features=dataset.columns[0:36]))\n",
    "\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os folds para a validação cruzada\n",
    "num_splits = 10\n",
    "kfold = KFold(n_splits=num_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.680856 (0.027867)\n",
      "CART: 0.682479 (0.025217)\n",
      "NB: 0.715411 (0.033750)\n",
      "SVM: 0.680528 (0.030234)\n",
      "LR: 0.761617 (0.026800)\n",
      "Bagging: 0.749972 (0.025425)\n",
      "RF: 0.759993 (0.023443)\n",
      "ET: 0.754173 (0.027037)\n",
      "Ada: 0.754489 (0.032907)\n",
      "GB: 0.760317 (0.020671)\n",
      "Voting: 0.749342 (0.030209)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modelagem\n",
    "\n",
    "# Definindo uma seed global para esta célula de código\n",
    "np.random.seed(42)\n",
    "\n",
    "# Divindindo o dataset em subconjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "# Listas para aramazenar os modelos, os resultados e os nomes dos modelos\n",
    "models = []\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Preparando os modelos e adicionando-os em uma lista\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('LR', LogisticRegression(max_iter=200)))\n",
    "\n",
    "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
    "base = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "# Criando os modelos para o VotingClassifier\n",
    "bases = []\n",
    "model1 = LogisticRegression(max_iter=200)\n",
    "bases.append(('Logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "bases.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "bases.append(('svm', model3))\n",
    "\n",
    "# Criando os ensembles e adicionando na lista de modelos\n",
    "models.append(('Bagging', BaggingClassifier(base_estimator=base, n_estimators=num_trees)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
    "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
    "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
    "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
    "models.append(('Voting', VotingClassifier(bases)))\n",
    "\n",
    "# Avaliando um modelo por vez\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot de comparação de modelos\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.suptitle('Comparação da Acurácia dos Modelos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os elementos do pipeline\n",
    "\n",
    "# Algoritmos que serão utilizados\n",
    "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
    "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
    "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
    "\n",
    "# Transformações que serão utilizadas\n",
    "standard_scaler = ('StandardScaler', StandardScaler())\n",
    "min_max_scaler = ('MinMaxScaler', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('LR', LogisticRegression(max_iter=200))])\n",
      "LR-orig: 0.761617 (0.026800)\n",
      "Pipeline(steps=[('RF', RandomForestClassifier(max_features=3))])\n",
      "RF-orig: 0.759671 (0.026159)\n",
      "Pipeline(steps=[('GB', GradientBoostingClassifier())])\n",
      "GB-orig: 0.760317 (0.020671)\n",
      "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
      "                ('LR', LogisticRegression(max_iter=200))])\n",
      "LR-padr: 0.760644 (0.027319)\n",
      "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
      "                ('RF', RandomForestClassifier(max_features=3))])\n",
      "RF-padr: 0.757734 (0.032485)\n",
      "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
      "                ('GB', GradientBoostingClassifier())])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m pipelines:\n\u001b[0;32m     28\u001b[0m     \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m---> 30\u001b[0m     cv_results \u001b[39m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[39m=\u001b[39;49mkfold, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m     results\u001b[39m.\u001b[39mappend(cv_results)\n\u001b[0;32m     32\u001b[0m     names\u001b[39m.\u001b[39mappend(name)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:233\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m loss\u001b[39m.\u001b[39mis_multi_class:\n\u001b[0;32m    231\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(original_y \u001b[39m==\u001b[39m k, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m--> 233\u001b[0m residual \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mnegative_gradient(\n\u001b[0;32m    234\u001b[0m     y, raw_predictions_copy, k\u001b[39m=\u001b[39;49mk, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    235\u001b[0m )\n\u001b[0;32m    237\u001b[0m \u001b[39m# induce regression tree on residuals\u001b[39;00m\n\u001b[0;32m    238\u001b[0m tree \u001b[39m=\u001b[39m DecisionTreeRegressor(\n\u001b[0;32m    239\u001b[0m     criterion\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion,\n\u001b[0;32m    240\u001b[0m     splitter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m     ccp_alpha\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mccp_alpha,\n\u001b[0;32m    250\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py:824\u001b[0m, in \u001b[0;36mMultinomialDeviance.negative_gradient\u001b[1;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnegative_gradient\u001b[39m(\u001b[39mself\u001b[39m, y, raw_predictions, k\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    809\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute negative gradient for the ``k``-th class.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \n\u001b[0;32m    811\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The index of the class.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39mreturn\u001b[39;00m y \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mnan_to_num(\n\u001b[1;32m--> 824\u001b[0m         np\u001b[39m.\u001b[39mexp(raw_predictions[:, k] \u001b[39m-\u001b[39m logsumexp(raw_predictions, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    825\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\special\\_logsumexp.py:115\u001b[0m, in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m# suppress warnings about log of zero\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(divide\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 115\u001b[0m     s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(tmp, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49mkeepdims)\n\u001b[0;32m    116\u001b[0m     \u001b[39mif\u001b[39;00m return_sign:\n\u001b[0;32m    117\u001b[0m         sgn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msign(s)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Montando os pipelines\n",
    "\n",
    "# Lista para armazenar os pipelines\n",
    "pipelines = []\n",
    "\n",
    "# Listas para aramazenar os resultados e os nomes dos modelos\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Dataset original\n",
    "pipelines.append(('LR-orig', Pipeline([reg_log])))\n",
    "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
    "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
    "\n",
    "# Dataset padronizado\n",
    "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log])))\n",
    "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
    "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
    "\n",
    "# Dataset normalizado\n",
    "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log])))\n",
    "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
    "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
    "\n",
    "# Executando os pipelines\n",
    "for name, model in pipelines:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot de comparação de modelos selecionados\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle('Comparação dos Modelos - Dataset original, padronizado e normalizado')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem tratamento de missings: LR-orig - Melhor: 0.761617 usando {'LR__penalty': 'l2', 'LR__solver': 'lbfgs'}\n",
      "Sem tratamento de missings: LR-padr - Melhor: 0.760644 usando {'LR__penalty': 'l2', 'LR__solver': 'lbfgs'}\n",
      "Sem tratamento de missings: LR-norm - Melhor: 0.760320 usando {'LR__penalty': 'none', 'LR__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# tuning da Regressão Logistica\n",
    "\n",
    "pipelines_reg_log = []\n",
    "\n",
    "# definindo os componentes do pipeline\n",
    "pipelines_reg_log.append(('LR-orig', Pipeline(steps=[reg_log])))\n",
    "pipelines_reg_log.append(('LR-padr', Pipeline(steps=[standard_scaler, reg_log])))\n",
    "pipelines_reg_log.append(('LR-norm', Pipeline(steps=[min_max_scaler, reg_log])))\n",
    "\n",
    "'''\n",
    "param_grid= {\n",
    "    'LR__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'LR__C' : np.logspace(-4, 4, 20),\n",
    "    'LR__solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'LR__max_iter' : [100, 1000,2500, 5000]\n",
    "}\n",
    "'''\n",
    "param_grid= {\n",
    "    'LR__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'LR__solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "}\n",
    "\n",
    "# prepara e executa o GridSearchCV\n",
    "for name, model in pipelines_reg_log:\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    # imprime a melhor configuração\n",
    "    msg = \"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem tratamento de missings: RF-orig - Melhor: 0.760638 usando {'RF__max_features': 1, 'RF__n_estimators': 200}\n",
      "Sem tratamento de missings: RF-padr - Melhor: 0.761620 usando {'RF__max_features': 1, 'RF__n_estimators': 200}\n",
      "Sem tratamento de missings: RF-norm - Melhor: 0.760316 usando {'RF__max_features': 1, 'RF__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning do Random Forest\n",
    "\n",
    "pipelines_random_forest = []\n",
    "\n",
    "# Definindo os componentes do pipeline\n",
    "pipelines_random_forest.append(('RF-orig', Pipeline(steps=[random_forest])))\n",
    "pipelines_random_forest.append(('RF-padr', Pipeline(steps=[standard_scaler, random_forest])))\n",
    "pipelines_random_forest.append(('RF-norm', Pipeline(steps=[min_max_scaler, random_forest])))\n",
    "\n",
    "param_grid = [{\n",
    "    'RF__n_estimators':[10,100,200],\n",
    "    'RF__max_features':[1,3],\n",
    "}]\n",
    "\n",
    "# prepara e executa o GridSearchCV\n",
    "for name, model in pipelines_random_forest:\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    # imprime a melhor configuração\n",
    "    msg = \"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem tratamento de missings: GB-orig - Melhor: 0.763867 usando {'GB__max_features': 3, 'GB__n_estimators': 200}\n",
      "Sem tratamento de missings: GB-padr - Melhor: 0.760635 usando {'GB__max_features': 3, 'GB__n_estimators': 200}\n",
      "Sem tratamento de missings: GB-norm - Melhor: 0.764193 usando {'GB__max_features': 1, 'GB__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Tuning do Gradient Boosting\n",
    "\n",
    "pipelines_gradient_boosting = []\n",
    "\n",
    "# Definindo os componentes do pipeline\n",
    "pipelines_gradient_boosting.append(('GB-orig', Pipeline(steps=[gradient_boosting])))\n",
    "pipelines_gradient_boosting.append(('GB-padr', Pipeline(steps=[standard_scaler, gradient_boosting])))\n",
    "pipelines_gradient_boosting.append(('GB-norm', Pipeline(steps=[min_max_scaler, gradient_boosting])))\n",
    "\n",
    "param_grid = [{\n",
    "    'GB__n_estimators':[10,100,200],\n",
    "    'GB__max_features':[1,3],\n",
    "}]\n",
    "\n",
    "# prepara e executa o GridSearchCV\n",
    "for name, model in pipelines_gradient_boosting:\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    # imprime a melhor configuração\n",
    "    msg = \"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m rescaledX \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_train)\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression(max_iter\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39mfit(rescaledX, Y_train)\n\u001b[0;32m      9\u001b[0m \u001b[39m# estimativa da acurácia no conjunto de teste\u001b[39;00m\n\u001b[0;32m     10\u001b[0m rescaledTextX \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# avaliação do modelo com o conjunto de testes\n",
    "\n",
    "# preparação do modelo\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(rescaledX, Y_train)\n",
    "\n",
    "# estimativa da acurácia no conjunto de teste\n",
    "rescaledTextX = scaler.transform(X_test)\n",
    "predictions = model.predict(rescaledTextX)\n",
    "print(accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparação do modelo com TODO o dataset\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "model.fit(rescaledX, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.29482875 -0.09547022  2.49089589 -4.20952017  0.35008246 -0.35023049\n",
      "  -0.80484126 -0.12629816 -0.03601818 -0.66977812 -0.22566098 -0.08045561\n",
      "   0.02222877  0.90751193 -0.10799294 -0.358167    0.36813532  1.35764048\n",
      "  -0.57491418 -0.43036282 -0.15968211 -0.30081306 -2.52855964 -1.98606822\n",
      "  -1.52125739 -2.19710239 -0.19927303 -0.28244231 -2.83833657 -2.04262989\n",
      "  -1.47152688 -1.96348862 -0.19944099 -0.28763846  0.12438647  0.76576084]]\n"
     ]
    }
   ],
   "source": [
    "# novos dados - não sabemos a classe\n",
    "data = {\n",
    "\"Marital status\": [1],\n",
    "\"Application mode\": [17],\n",
    "\"Application order\": [5],\n",
    "\"Course\": [171],\n",
    "\"Daytime/evening attendance\": [1],\n",
    "\"Previous qualification\": [1],\n",
    "\"Previous qualification (grade)\": [122.0],\n",
    "\"Nacionality\": [1],\n",
    "\"Mother's qualification\": [19],\n",
    "\"Father's qualification\": [12],\n",
    "\"Mother's occupation\": [5],\n",
    "\"Father's occupation\": [9],\n",
    "\"Admission grade\": [127.3],\n",
    "\"Displaced\": [1],\n",
    "\"Educational special needs\": [0],\n",
    "\"Debtor\": [0],\n",
    "\"Tuition fees up to date\": [1],\n",
    "\"Gender\": [1],\n",
    "\"Scholarship holder\": [0],\n",
    "\"Age at enrollment\": [20],\n",
    "\"International\": [0],\n",
    "\"Curricular units 1st sem (credited)\": [0],\n",
    "\"Curricular units 1st sem (enrolled)\": [0],\n",
    "\"Curricular units 1st sem (evaluations)\": [0],\n",
    "\"Curricular units 1st sem (approved)\": [0],\n",
    "\"Curricular units 1st sem (grade)\": [0.0],\n",
    "\"Curricular units 1st sem (without evaluations)\":[0],\n",
    "\"Curricular units 2nd sem (credited)\": [0],\n",
    "\"Curricular units 2nd sem (enrolled)\": [0],\n",
    "\"Curricular units 2nd sem (evaluations)\": [0],\n",
    "\"Curricular units 2nd sem (approved)\": [0],\n",
    "\"Curricular units 2nd sem (grade)\": [0.0],\n",
    "\"Curricular units 2nd sem (without evaluations)\": [0],\n",
    "\"Unemployment rate\": [10.8],\n",
    "\"Inflation rate\": [1.4],\n",
    "\"GDP\": [1.74],\n",
    "}\n",
    "\n",
    "atributos = [\"Marital status\",\"Application mode\",\"Application order\",\"Course\",\"Daytime/evening attendance\",\"Previous qualification\",\"Previous qualification (grade)\",\"Nacionality\",\"Mother's qualification\",\"Father's qualification\",\"Mother's occupation\",\"Father's occupation\",\"Admission grade\",\"Displaced\",\"Educational special needs\",\"Debtor\",\"Tuition fees up to date\",\"Gender\",\"Scholarship holder\",\"Age at enrollment\",\"International\",\"Curricular units 1st sem (credited)\",\"Curricular units 1st sem (enrolled)\",\"Curricular units 1st sem (evaluations)\",\"Curricular units 1st sem (approved)\",\"Curricular units 1st sem (grade)\",\"Curricular units 1st sem (without evaluations)\",\"Curricular units 2nd sem (credited)\",\"Curricular units 2nd sem (enrolled)\",\"Curricular units 2nd sem (evaluations)\",\"Curricular units 2nd sem (approved)\",\"Curricular units 2nd sem (grade)\",\"Curricular units 2nd sem (without evaluations)\",\"Unemployment rate\",\"Inflation rate\",\"GDP\"]\n",
    "entrada = pd.DataFrame(data, columns=atributos)\n",
    "\n",
    "array_entrada = entrada.values\n",
    "X_entrada = array_entrada[:,0:36].astype(float)\n",
    "\n",
    "# padronização nos dados de entrada usando o scaler utilizado em X\n",
    "rescaledEntradaX = scaler.transform(X_entrada)\n",
    "print(rescaledEntradaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dropout']\n"
     ]
    }
   ],
   "source": [
    "# predição de classes dos dados de entrada\n",
    "saidas = model.predict(rescaledEntradaX)\n",
    "print(saidas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
