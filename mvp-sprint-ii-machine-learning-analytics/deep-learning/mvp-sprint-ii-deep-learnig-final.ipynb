{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sklearn.metrics as skm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(X_dataset, y_dataset, classes, n_samples):\n",
    "    if n_samples is None:\n",
    "        img_samples = X_dataset.shape[0]\n",
    "    else:\n",
    "        img_samples = n_samples\n",
    "\n",
    "    df_aux = pd.DataFrame(columns=['id', 'label'])\n",
    "\n",
    "    list_aux = []\n",
    "\n",
    "    for i in range(img_samples):\n",
    "        nm_file = str(i)+'-'+str([classes[x] for x in y_dataset[i]]).strip('[]').strip('\\'')+'.'+'png'\n",
    "        sample = {'id':nm_file, 'label':str([classes[x] for x in y_dataset[i]]).strip('[]').strip('\\'')}\n",
    "        list_aux.append(sample)\n",
    "\n",
    "    return pd.concat([df_aux, pd.DataFrame(list_aux)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files(X_dataset, y_dataset, classes, dir, n_samples):\n",
    "    if n_samples is None:\n",
    "        img_samples = X_dataset.shape[0]\n",
    "    else:\n",
    "        img_samples = n_samples\n",
    "\n",
    "    for i in range(img_samples):\n",
    "        nm_file = str(i)+'-'+str([classes[x] for x in y_dataset[i]]).strip('[]').strip('\\'')+'.'+'png'\n",
    "        img = X_dataset[i]\n",
    "        plt.imsave(dir + nm_file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(dir):\n",
    "    if os.path.exists(dir):\n",
    "        for file in os.listdir(dir):\n",
    "            os.remove(dir+file)\n",
    "    else:\n",
    "        os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./train/\"\n",
    "test_dir = \"./test/\" \n",
    "\n",
    "create_directory(train_dir)\n",
    "create_directory(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-frog.png</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-truck.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-truck.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-deer.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-automobile.png</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       label\n",
       "0        0-frog.png        frog\n",
       "1       1-truck.png       truck\n",
       "2       2-truck.png       truck\n",
       "3        3-deer.png        deer\n",
       "4  4-automobile.png  automobile"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = 500 #X_train.shape[0]\n",
    "\n",
    "create_files(X_train, y_train, cifar10_classes, train_dir, train_samples)\n",
    "\n",
    "train_df = prepare_dataset(X_train, y_train, cifar10_classes, train_samples)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-cat.png</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-ship.png</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-ship.png</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-airplane.png</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-frog.png</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     label\n",
       "0       0-cat.png       cat\n",
       "1      1-ship.png      ship\n",
       "2      2-ship.png      ship\n",
       "3  3-airplane.png  airplane\n",
       "4      4-frog.png      frog"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = 100 #X_test.shape[0]\n",
    "\n",
    "create_files(X_test, y_test, cifar10_classes, test_dir, test_samples)\n",
    "\n",
    "test_df = prepare_dataset(X_test, y_test, cifar10_classes, test_samples)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens para treinamento: 500\n",
      "Total de imagens para teste      : 100\n"
     ]
    }
   ],
   "source": [
    "print('Total de imagens para treinamento: %s' % len(os.listdir(train_dir)))\n",
    "print('Total de imagens para teste      : %s' % len(os.listdir(test_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 375 validated image filenames belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                validation_split=0.25)\n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=train_df,\n",
    "directory=train_dir,\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"training\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))\n",
    "\n",
    "valid_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=train_df,\n",
    "directory=train_dir,\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"validation\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df,\n",
    "directory=test_dir,\n",
    "x_col=\"id\",\n",
    "y_col=None,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,618\n",
      "Trainable params: 508,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32,32,3), activation=('relu')))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation=('relu')))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', activation=('relu')))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', activation=('relu')))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11/11 [==============================] - 12s 469ms/step - loss: 2.3129 - accuracy: 0.0904 - val_loss: 2.3120 - val_accuracy: 0.1667\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 2.2884 - accuracy: 0.0991 - val_loss: 2.2870 - val_accuracy: 0.1979\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 2.2679 - accuracy: 0.1370 - val_loss: 2.2793 - val_accuracy: 0.2396\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 2.2140 - accuracy: 0.1603 - val_loss: 2.1991 - val_accuracy: 0.2083\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 2.0734 - accuracy: 0.2507 - val_loss: 2.0866 - val_accuracy: 0.3125\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 1.9186 - accuracy: 0.2945 - val_loss: 2.1232 - val_accuracy: 0.2188\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 1.8806 - accuracy: 0.3236 - val_loss: 2.1237 - val_accuracy: 0.2292\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 2s 136ms/step - loss: 1.7342 - accuracy: 0.3382 - val_loss: 1.9069 - val_accuracy: 0.3021\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 1.6836 - accuracy: 0.4023 - val_loss: 2.1117 - val_accuracy: 0.2083\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 1.6189 - accuracy: 0.3732 - val_loss: 1.8483 - val_accuracy: 0.2812\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 2s 135ms/step - loss: 1.5982 - accuracy: 0.4034 - val_loss: 1.7710 - val_accuracy: 0.3438\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 1.5043 - accuracy: 0.4315 - val_loss: 1.9738 - val_accuracy: 0.3125\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 1.4677 - accuracy: 0.4665 - val_loss: 2.1089 - val_accuracy: 0.3021\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 1.3918 - accuracy: 0.5160 - val_loss: 1.8815 - val_accuracy: 0.3333\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 1.2729 - accuracy: 0.5199 - val_loss: 1.9205 - val_accuracy: 0.3646\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 2s 148ms/step - loss: 1.1946 - accuracy: 0.5481 - val_loss: 1.9033 - val_accuracy: 0.3854\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 1.0908 - accuracy: 0.5831 - val_loss: 2.0601 - val_accuracy: 0.3125\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 1.0342 - accuracy: 0.6335 - val_loss: 1.9243 - val_accuracy: 0.4167\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 0.9567 - accuracy: 0.6822 - val_loss: 2.1192 - val_accuracy: 0.3646\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.8909 - accuracy: 0.6939 - val_loss: 2.0382 - val_accuracy: 0.3750\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 0.8101 - accuracy: 0.7026 - val_loss: 2.2853 - val_accuracy: 0.3854\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.6859 - accuracy: 0.7609 - val_loss: 2.2463 - val_accuracy: 0.3750\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.6540 - accuracy: 0.7551 - val_loss: 2.3424 - val_accuracy: 0.3854\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.5605 - accuracy: 0.8047 - val_loss: 2.7694 - val_accuracy: 0.3125\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.5285 - accuracy: 0.8251 - val_loss: 2.5857 - val_accuracy: 0.3646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1802f1a7190>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step_size = train_generator.n//train_generator.batch_size\n",
    "validation_step_size = valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "model.fit(x=train_generator,\n",
    "          steps_per_epoch=train_step_size,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=validation_step_size,\n",
    "          epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
